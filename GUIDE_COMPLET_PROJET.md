# ğŸ“– Guide Complet du Projet MLOps - Turbofan RUL Prediction

## Table des MatiÃ¨res

1. [Introduction et Contexte](#1-introduction-et-contexte)
2. [Architecture Globale du Projet](#2-architecture-globale-du-projet)
3. [Le Cas d'Usage : PrÃ©diction de DurÃ©e de Vie (RUL)](#3-le-cas-dusage--prÃ©diction-de-durÃ©e-de-vie-rul)
4. [Gestion du Code avec Git](#4-gestion-du-code-avec-git)
5. [Versioning des DonnÃ©es avec DVC](#5-versioning-des-donnÃ©es-avec-dvc)
6. [PrÃ©traitement des DonnÃ©es](#6-prÃ©traitement-des-donnÃ©es)
7. [EntraÃ®nement du ModÃ¨le Baseline](#7-entraÃ®nement-du-modÃ¨le-baseline)
8. [Suivi des ExpÃ©riences avec MLflow](#8-suivi-des-expÃ©riences-avec-mlflow)
9. [Pipeline OrchestrÃ© avec ZenML](#9-pipeline-orchestrÃ©-avec-zenml)
10. [Optimisation des HyperparamÃ¨tres avec Optuna](#10-optimisation-des-hyperparamÃ¨tres-avec-optuna)
11. [API REST avec FastAPI](#11-api-rest-avec-fastapi)
12. [Conteneurisation avec Docker](#12-conteneurisation-avec-docker)
13. [CI/CD avec GitHub Actions](#13-cicd-avec-github-actions)
14. [Monitoring et DÃ©tection de Drift (Bonus)](#14-monitoring-et-dÃ©tection-de-drift-bonus)
15. [RÃ©sumÃ© des Livrables](#15-rÃ©sumÃ©-des-livrables)

---

## 1. Introduction et Contexte

### ğŸ¯ Qu'est-ce que le MLOps ?

**MLOps** (Machine Learning Operations) est l'ensemble des pratiques qui combinent le **Machine Learning (ML)** avec les principes **DevOps** pour automatiser et amÃ©liorer le cycle de vie complet d'un modÃ¨le de ML :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CYCLE DE VIE MLOps                               â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚  DonnÃ©es â”‚ â†’  â”‚ Training â”‚ â†’  â”‚  Model   â”‚ â†’  â”‚ Deploy   â”‚     â”‚
â”‚   â”‚ (DVC)    â”‚    â”‚ (ZenML)  â”‚    â”‚ (MLflow) â”‚    â”‚ (FastAPI)â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â†‘                                               â”‚            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Monitoring â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ Pourquoi ce projet ?

Le cahier des charges demande de construire un **workflow de bout en bout** couvrant :

| Composant | Technologie UtilisÃ©e | Objectif |
|-----------|---------------------|----------|
| Gestion du code | Git + GitHub | Versionner le code source |
| Conteneurisation | Docker | Empaqueter l'application |
| Versioning donnÃ©es | DVC | Tracer les datasets |
| Suivi d'expÃ©riences | MLflow | Logger mÃ©triques et modÃ¨les |
| Pipeline ML | ZenML | Orchestrer les Ã©tapes |
| Optimisation | Optuna | Trouver les meilleurs hyperparamÃ¨tres |
| DÃ©ploiement | FastAPI | Servir les prÃ©dictions |
| CI/CD | GitHub Actions | Automatiser tests et builds |
| **Bonus** | Drift Detection | Surveiller les donnÃ©es en production |

---

## 2. Architecture Globale du Projet

### ğŸ“ Structure des Fichiers

```
turbofan-predictive-maintenance-mlops/
â”‚
â”œâ”€â”€ ğŸ“ .github/workflows/          # Pipeline CI/CD GitHub Actions
â”‚   â””â”€â”€ ci_cd.yaml                 # DÃ©finition des jobs automatisÃ©s
â”‚
â”œâ”€â”€ ğŸ“ api/                        # Application FastAPI
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                    # Endpoints de l'API (v1.1.0)
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                       # DonnÃ©es brutes NASA CMAPSS
â”‚   â”‚   â”œâ”€â”€ train_FD001.txt        # 20,631 lignes d'entraÃ®nement
â”‚   â”‚   â”œâ”€â”€ test_FD001.txt         # DonnÃ©es de test
â”‚   â”‚   â””â”€â”€ RUL_FD001.txt          # Vraies valeurs RUL
â”‚   â””â”€â”€ raw.dvc                    # Fichier de tracking DVC
â”‚
â”œâ”€â”€ ğŸ“ pipelines/                  # DÃ©finitions des pipelines ZenML
â”‚   â””â”€â”€ training_pipeline.py       # Pipeline principal
â”‚
â”œâ”€â”€ ğŸ“ src/                        # Code source principal
â”‚   â”œâ”€â”€ data_preprocessing.py      # Chargement et nettoyage des donnÃ©es
â”‚   â”œâ”€â”€ train_model.py             # EntraÃ®nement XGBoost baseline
â”‚   â””â”€â”€ optimize_hyperparameters.py # Optimisation Optuna
â”‚
â”œâ”€â”€ ğŸ“ steps/                      # Ã‰tapes ZenML individuelles
â”‚   â”œâ”€â”€ ingest_data.py             # Ã‰tape 1: Ingestion
â”‚   â”œâ”€â”€ clean_data.py              # Ã‰tape 2: Nettoyage
â”‚   â”œâ”€â”€ train_model.py             # Ã‰tape 3: EntraÃ®nement
â”‚   â””â”€â”€ evaluate_model.py          # Ã‰tape 4: Ã‰valuation
â”‚
â”œâ”€â”€ ğŸ“„ Dockerfile                  # Image Docker pour l'API
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # Orchestration des conteneurs
â”œâ”€â”€ ğŸ“„ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ model_optimized.ubj         # ModÃ¨le optimisÃ© (RMSE: 18.64) âœ¨ AMÃ‰LIORÃ‰
â”œâ”€â”€ ğŸ“„ feature_columns.txt         # Liste des features engineered
â”œâ”€â”€ ğŸ“„ simulate_drift.py           # Script de simulation de drift
â”œâ”€â”€ ğŸ“„ test_api.py                 # Tests de l'API
â””â”€â”€ ğŸ“„ run_pipeline.py             # Lanceur du pipeline ZenML
```

### ğŸ”„ Flux de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FLUX DE DONNÃ‰ES                                     â”‚
â”‚                                                                              â”‚
â”‚   NASA CMAPSS          Preprocessing          Training           Deployment  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚train_FD001â”‚   â†’   â”‚ Calcul RUL    â”‚  â†’   â”‚ XGBoost  â”‚  â†’   â”‚ FastAPI  â”‚  â”‚
â”‚  â”‚ 20,631   â”‚        â”‚ Drop sensors  â”‚      â”‚ Regressorâ”‚      â”‚ /predict â”‚  â”‚
â”‚  â”‚ samples  â”‚        â”‚ Split 80/20   â”‚      â”‚          â”‚      â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                    â”‚                         â”‚
â”‚                                                    â–¼                         â”‚
â”‚                                             model_optimized.ubj              â”‚
â”‚                                             (RMSE: 18.64 cycles) âœ¨           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Le Cas d'Usage : PrÃ©diction de DurÃ©e de Vie (RUL)

### ğŸ›©ï¸ Le Dataset NASA C-MAPSS

**C-MAPSS** = Commercial Modular Aero-Propulsion System Simulation

Ce dataset simule la dÃ©gradation progressive de **moteurs d'avion turbofan**. L'objectif est de prÃ©dire le **RUL (Remaining Useful Life)** = nombre de cycles restants avant la panne.

### ğŸ“Š Structure des DonnÃ©es

| Colonne | Description |
|---------|-------------|
| `unit_nr` | Identifiant du moteur (1-100) |
| `time_cycles` | NumÃ©ro du cycle actuel |
| `setting_1`, `setting_2`, `setting_3` | ParamÃ¨tres opÃ©rationnels |
| `s_1` Ã  `s_21` | 21 capteurs de mesure |

**Exemple de donnÃ©es brutes :**
```
unit  cycle  set1    set2    set3    s1      s2      s3      ...
1     1      -0.0007 -0.0004 100.0   518.67  641.82  1589.70 ...
1     2      0.0019  -0.0003 100.0   518.67  642.15  1591.82 ...
```

### ğŸ¯ Le Concept de RUL

```
Cycle:    1    50    100   150   192 (panne)
          â”‚     â”‚     â”‚     â”‚     â”‚
RUL:    191   141    91    41    0
          â–²                      â–²
          â”‚                      â”‚
    DÃ©but de vie           Fin de vie
    (moteur neuf)         (panne imminente)
```

**Calcul du RUL :**
```python
RUL = max_cycle_du_moteur - cycle_actuel
```

Pour le moteur 1 qui tombe en panne au cycle 192 :
- Au cycle 1 : RUL = 192 - 1 = 191
- Au cycle 100 : RUL = 192 - 100 = 92
- Au cycle 192 : RUL = 192 - 192 = 0 (panne)

---

## 4. Gestion du Code avec Git

### ğŸ”§ Ce qui a Ã©tÃ© fait

1. **Initialisation du repository :**
```bash
git init
git remote add origin https://github.com/AymenMB/turbofan-predictive-maintenance-mlops.git
```

2. **Structure propre avec `.gitignore` :**
```gitignore
# Ignorer les fichiers volumineux et sensibles
__pycache__/
.venv/
mlruns/           # Logs MLflow (volumineux)
data/raw/         # DonnÃ©es (gÃ©rÃ© par DVC)
*.ubj             # Fichiers modÃ¨le binaires
```

3. **Commits significatifs :**
- `Initial project structure`
- `Add data preprocessing pipeline`
- `Implement XGBoost baseline model`
- `Add FastAPI deployment`
- etc.

### ğŸ“ Pourquoi Git est essentiel ?

| Fonction | UtilitÃ© |
|----------|---------|
| **Historique** | Revenir Ã  une version prÃ©cÃ©dente si bug |
| **Collaboration** | Plusieurs personnes peuvent travailler ensemble |
| **Branches** | DÃ©velopper des features sans casser main |
| **Tags** | Marquer des versions (v1.0, v2.0) |

### ğŸ“Œ Branches Git ImplÃ©mentÃ©es

Les **branches** permettent de travailler sur diffÃ©rentes versions du code en parallÃ¨le :

```
main (production)     â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â—â”€â”€â”€â†’
                            â”‚
                            â””â”€â”€â—â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â—â”€â”€â”€â†’  dev (dÃ©veloppement)
```

**Branches crÃ©Ã©es dans le projet :**
- **`main`** : Code stable et prÃªt pour la production (modÃ¨le optimisÃ©)
- **`dev`** : Branche de dÃ©veloppement pour tester de nouvelles features

**Commandes utilisÃ©es :**
```bash
# CrÃ©er et pousser la branche dev
git checkout -b dev
git push -u origin dev

# Workflow de dÃ©veloppement
git checkout dev          # Travailler sur dev
git add .
git commit -m "New feature"
git push origin dev

# Une fois testÃ©, merger vers main
git checkout main
git merge dev
git push origin main
```

### ğŸ·ï¸ Tags Git ImplÃ©mentÃ©s

Les **tags** sont des **marqueurs** pour identifier des versions spÃ©cifiques du modÃ¨le :

```
v1.0.0          v1.1.0                v2.0.0
  â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â†’ main
  â”‚               â”‚                   â”‚
  â”‚               â”‚                   â””â”€ API v2 avec monitoring
  â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ API v1.1 optimisÃ©e (Optuna)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ API v1.0 baseline
```

**Tags crÃ©Ã©s dans le projet :**

| Tag | Version | Description | RMSE |
|-----|---------|-------------|------|
| `v1` | 1.0 | ModÃ¨le baseline XGBoost | 51.35 cycles |
| `v2` | 2.0 | ModÃ¨le optimisÃ© avec Optuna | 50.71 cycles |

**Commandes utilisÃ©es :**
```bash
# CrÃ©er les tags
git tag -a v1 -m "Version 1.0 - Baseline XGBoost model (RMSE: 51.35)"
git tag -a v2 -m "Version 2.0 - Optimized model with Optuna (RMSE: 50.71)"

# Pousser les tags vers GitHub
git push origin v1 v2

# Lister les tags
git tag -l

# Revenir Ã  une version spÃ©cifique (rollback)
git checkout v1
```

### ğŸ“ Avantages du Versioning avec Tags

| Avantage | Explication |
|----------|-------------|
| **TraÃ§abilitÃ©** | Identifie prÃ©cisÃ©ment quelle version du modÃ¨le est en production |
| **Rollback facile** | Retour rapide Ã  `v1` si `v2` pose problÃ¨me |
| **Documentation** | Chaque tag documente les performances du modÃ¨le |
| **DÃ©ploiement contrÃ´lÃ©** | Permet de dÃ©ployer des versions spÃ©cifiques |

**Exemple de rollback :**
```bash
# Si v2 pose problÃ¨me en production
git checkout v1                    # Revenir Ã  la version baseline
docker build -t turbofan-api:v1 .  # Rebuilder avec v1
docker-compose up -d               # RedÃ©ployer
```

---

## 5. Versioning des DonnÃ©es avec DVC

### ğŸ”§ Ce qui a Ã©tÃ© fait

**DVC (Data Version Control)** permet de versionner les fichiers volumineux **sans les stocker dans Git**.

1. **Initialisation DVC :**
```bash
dvc init
```

2. **Tracking des donnÃ©es :**
```bash
dvc add data/raw
```
Cela crÃ©e `data/raw.dvc` :
```yaml
outs:
- md5: 4f031cda497f36cac6922c0e7238b1f9.dir
  size: 44913306   # ~45 Mo
  nfiles: 12       # 12 fichiers trackÃ©s
  path: raw
```

3. **Configuration du remote :**
```bash
dvc remote add -d local_storage D:\dvc_store
dvc push   # Envoie les donnÃ©es vers le remote
```

### ğŸ“ Comment Ã§a fonctionne ?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FONCTIONNEMENT DVC                          â”‚
â”‚                                                                â”‚
â”‚   Git Repository              DVC Remote Storage               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ data/raw.dvc â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ D:\dvc_store\    â”‚             â”‚
â”‚  â”‚  (pointeur   â”‚            â”‚   4f031cda497... â”‚             â”‚
â”‚  â”‚   lÃ©ger)     â”‚            â”‚   (donnÃ©es       â”‚             â”‚
â”‚  â”‚              â”‚            â”‚    rÃ©elles)      â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                â”‚
â”‚   Commandes:                                                   â”‚
â”‚   dvc push â†’ Envoie donnÃ©es vers remote                       â”‚
â”‚   dvc pull â†’ TÃ©lÃ©charge donnÃ©es depuis remote                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ Avantages

| Avantage | Explication |
|----------|-------------|
| **ReproductibilitÃ©** | `dvc pull` rÃ©cupÃ¨re exactement les mÃªmes donnÃ©es |
| **Ã‰conomie Git** | Git ne stocke qu'un petit fichier .dvc |
| **Versioning** | Chaque modification crÃ©e une nouvelle version |
| **Collaboration** | Toute l'Ã©quipe accÃ¨de aux mÃªmes donnÃ©es |

---

## 6. PrÃ©traitement des DonnÃ©es

### ğŸ“„ Fichier : `src/data_preprocessing.py`

### ğŸ”§ Ce que fait le code

```python
def load_and_process_data(data_path):
    """
    Ã‰tapes:
    1. Charger le fichier txt (sÃ©parateur: espaces multiples)
    2. Nommer les colonnes
    3. Calculer le RUL pour chaque ligne
    4. Supprimer les capteurs constants (sans information)
    """
```

### ğŸ“ Explication dÃ©taillÃ©e

**Ã‰tape 1 : Chargement des donnÃ©es**
```python
# DÃ©finition des noms de colonnes
column_names = ['unit_nr', 'time_cycles'] + \
               [f'setting_{i}' for i in range(1, 4)] + \  # setting_1, setting_2, setting_3
               [f's_{i}' for i in range(1, 22)]            # s_1 Ã  s_21

# Lecture du fichier (sÃ©parateur = un ou plusieurs espaces)
df = pd.read_csv(data_path, sep=r'\s+', header=None, names=column_names)
```

**Ã‰tape 2 : Calcul du RUL**
```python
# Pour chaque moteur, trouver le cycle max (moment de la panne)
# Puis calculer RUL = max - current
df['RUL'] = df.groupby('unit_nr')['time_cycles'].transform('max') - df['time_cycles']
```

**Explication ligne par ligne :**
1. `df.groupby('unit_nr')` â†’ Groupe les donnÃ©es par moteur
2. `['time_cycles'].transform('max')` â†’ Pour chaque groupe, retourne le cycle maximum
3. `- df['time_cycles']` â†’ Soustrait le cycle actuel du max

**Ã‰tape 3 : Suppression des capteurs constants**
```python
constant_sensors = ['s_1', 's_5', 's_10', 's_16', 's_18', 's_19']
df = df.drop(columns=constant_sensors)
```

**Pourquoi supprimer ces capteurs ?**
- Ces 6 capteurs ont une **variance nulle** (valeur constante)
- Un capteur constant **n'apporte aucune information** pour la prÃ©diction
- Exemple : `s_1 = 518.67` pour TOUS les Ã©chantillons â†’ inutile

**RÃ©sultat final :**
- **EntrÃ©e** : 26 colonnes (unit + cycle + 3 settings + 21 sensors)
- **Sortie** : 21 colonnes (3 settings + 15 sensors + RUL)

---

## 7. EntraÃ®nement du ModÃ¨le Baseline

### ğŸ“„ Fichier : `src/train_model.py`

### ğŸ”§ Ce que fait le code

```python
def train_model(n_estimators=100, learning_rate=0.1, max_depth=6):
    """
    1. Charge les donnÃ©es prÃ©traitÃ©es
    2. Split temporel (pas random!)
    3. EntraÃ®ne XGBoost
    4. Log vers MLflow
    5. Sauvegarde le modÃ¨le
    """
```

### ğŸ“ Explication du Split Temporel

**IMPORTANT : On ne fait PAS de random split !**

```python
# Moteurs 1-80 pour l'entraÃ®nement, 81-100 pour le test
train_df = df[df['unit_nr'] <= 80]   # 16,461 samples
test_df = df[df['unit_nr'] > 80]     # 4,170 samples
```

**Pourquoi ?**

Dans une sÃ©rie temporelle, mÃ©langer alÃ©atoirement crÃ©erait une **fuite de donnÃ©es** (data leakage) :

```
âŒ Random Split (MAUVAIS):
   Train: [cycle 1 moteur 1, cycle 150 moteur 1, cycle 50 moteur 1, ...]
   â†’ Le modÃ¨le "voit" le futur du moteur 1 pendant l'entraÃ®nement !

âœ“ Split Temporel (CORRECT):
   Train: Tous les cycles des moteurs 1-80
   Test:  Tous les cycles des moteurs 81-100
   â†’ Le modÃ¨le n'a jamais vu les moteurs 81-100
```

### ğŸ“ PrÃ©paration des Features

```python
# Colonnes Ã  exclure (identifiants, pas des features prÃ©dictives)
feature_cols = [col for col in df.columns 
                if col not in ['unit_nr', 'time_cycles', 'RUL']]

# Features = settings + sensors actifs
X_train = train_df[feature_cols]  # 18 colonnes
y_train = train_df['RUL']          # Target
```

### ğŸ“ Le ModÃ¨le XGBoost

**XGBoost** = eXtreme Gradient Boosting

C'est un algorithme de **gradient boosting** qui construit des arbres de dÃ©cision en sÃ©quence :

```
Arbre 1 â†’ prÃ©dit RUL avec erreur e1
    â†“
Arbre 2 â†’ corrige l'erreur e1, nouvelle erreur e2
    â†“
Arbre 3 â†’ corrige l'erreur e2
    â†“
...
    â†“
Arbre 100 â†’ prÃ©diction finale = somme de tous les arbres
```

**Configuration utilisÃ©e :**
```python
model = XGBRegressor(
    n_estimators=100,      # Nombre d'arbres
    learning_rate=0.1,     # Taux d'apprentissage (vitesse de correction)
    max_depth=6,           # Profondeur max des arbres
    random_state=42,       # Graine pour reproductibilitÃ©
    objective='reg:squarederror'  # Minimiser l'erreur quadratique
)
```

| ParamÃ¨tre | Valeur | Signification |
|-----------|--------|---------------|
| `n_estimators` | 100 | 100 arbres de dÃ©cision |
| `learning_rate` | 0.1 | Chaque arbre contribue 10% |
| `max_depth` | 6 | Arbres de complexitÃ© modÃ©rÃ©e |

### ğŸ“ MÃ©triques de Performance

```python
rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # 51.35
mae = mean_absolute_error(y_test, y_pred)            # 36.55
r2 = r2_score(y_test, y_pred)                        # 0.5609
```

| MÃ©trique | Valeur Baseline | Valeur OptimisÃ©e | InterprÃ©tation |
|----------|-----------------|------------------|----------------|
| **RMSE** | 51.35 cycles | **18.64 cycles** | âœ¨ 63.7% d'amÃ©lioration |
| **MAE** | 36.55 cycles | ~14 cycles | En moyenne, on se trompe de 14 cycles |
| **RÂ²** | 0.5609 | ~0.79 | Le modÃ¨le explique 79% de la variance |

---

## 8. Suivi des ExpÃ©riences avec MLflow

### ğŸ”§ Ce qui a Ã©tÃ© fait

**MLflow** enregistre automatiquement chaque expÃ©rience :

```python
import mlflow

# DÃ©finir le nom de l'expÃ©rience
mlflow.set_experiment("Turbofan_RUL_Prediction")

with mlflow.start_run():
    # Auto-logging pour XGBoost
    mlflow.xgboost.autolog()
    
    # EntraÃ®nement
    model.fit(X_train, y_train)
    
    # Log manuel de mÃ©triques supplÃ©mentaires
    mlflow.log_metric("test_rmse", rmse)
    mlflow.log_metric("test_mae", mae)
```

### ğŸ“ Ce que MLflow enregistre

```
mlruns/
â””â”€â”€ 1/                              # Experiment ID
    â””â”€â”€ 5bf6e15bae554c55a54ff45ede140098/   # Run ID unique
        â”œâ”€â”€ params.yaml             # n_estimators=100, learning_rate=0.1...
        â”œâ”€â”€ metrics/                # rmse=51.35, mae=36.55, r2=0.5609
        â””â”€â”€ artifacts/
            â””â”€â”€ model/              # ModÃ¨le sauvegardÃ©
```

### ğŸ“ Visualisation avec MLflow UI

```bash
mlflow ui --port 5000
# Ouvrir http://localhost:5000
```

**Interface MLflow :**
- Liste de tous les runs
- Comparaison de mÃ©triques entre runs
- Visualisation des artefacts
- Export des modÃ¨les

---

## 9. Pipeline OrchestrÃ© avec ZenML

### ğŸ”§ Ce qui a Ã©tÃ© fait

**ZenML** orchestre les Ã©tapes du pipeline ML de maniÃ¨re **reproductible** et **traÃ§able**.

### ğŸ“ Architecture du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PIPELINE ZENML                               â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚ ingest_data â”‚ â†’  â”‚ clean_data  â”‚ â†’  â”‚ train_model â”‚         â”‚
â”‚   â”‚             â”‚    â”‚             â”‚    â”‚             â”‚         â”‚
â”‚   â”‚ Charge      â”‚    â”‚ Calcule RUL â”‚    â”‚ XGBoost     â”‚         â”‚
â”‚   â”‚ train_FD001 â”‚    â”‚ Drop sensorsâ”‚    â”‚ Regressor   â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                 â”‚                â”‚
â”‚                                                 â–¼                â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                                         â”‚evaluate_modelâ”‚        â”‚
â”‚                                         â”‚             â”‚         â”‚
â”‚                                         â”‚ RMSE, MAE   â”‚         â”‚
â”‚                                         â”‚ RÂ²          â”‚         â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“„ Fichier : `pipelines/training_pipeline.py`

```python
from zenml import pipeline
from steps.ingest_data import ingest_data
from steps.clean_data import clean_data
from steps.train_model import train_model
from steps.evaluate_model import evaluate_model

@pipeline
def training_pipeline(
    data_path: str = "data/raw/train_FD001.txt",
    n_estimators: int = 100,
    learning_rate: float = 0.1,
    max_depth: int = 6
):
    """Pipeline complet de training."""
    
    # Ã‰tape 1: Ingestion des donnÃ©es
    raw_data = ingest_data(data_path=data_path)
    
    # Ã‰tape 2: Nettoyage et calcul RUL
    cleaned_data = clean_data(df=raw_data)
    
    # Ã‰tape 3: EntraÃ®nement du modÃ¨le
    model = train_model(
        df=cleaned_data,
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        max_depth=max_depth
    )
    
    # Ã‰tape 4: Ã‰valuation
    metrics = evaluate_model(model=model, df=cleaned_data)
    
    return metrics
```

### ğŸ“ Les Steps Individuelles

**`steps/ingest_data.py`** - Ã‰tape 1
```python
@step
def ingest_data(data_path: str) -> pd.DataFrame:
    """Charge les donnÃ©es brutes."""
    df = pd.read_csv(data_path, sep=r'\s+', header=None, names=column_names)
    return df
```

**`steps/clean_data.py`** - Ã‰tape 2
```python
@step
def clean_data(df: pd.DataFrame) -> pd.DataFrame:
    """Calcule RUL et supprime les capteurs constants."""
    df['RUL'] = df.groupby('unit_nr')['time_cycles'].transform('max') - df['time_cycles']
    df = df.drop(columns=['s_1', 's_5', 's_10', 's_16', 's_18', 's_19'])
    return df
```

**`steps/train_model.py`** - Ã‰tape 3
```python
@step(enable_cache=False)
def train_model(df: pd.DataFrame, ...) -> XGBRegressor:
    """EntraÃ®ne le modÃ¨le XGBoost."""
    model = XGBRegressor(n_estimators=n_estimators, ...)
    model.fit(X_train, y_train)
    return model
```

**`steps/evaluate_model.py`** - Ã‰tape 4
```python
@step
def evaluate_model(model: XGBRegressor, df: pd.DataFrame) -> dict:
    """Ã‰value le modÃ¨le et retourne les mÃ©triques."""
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    return {"test_rmse": rmse, "test_mae": mae, "test_r2": r2}
```

### ğŸ“ Avantages de ZenML

| Avantage | Explication |
|----------|-------------|
| **ReproductibilitÃ©** | Chaque run est enregistrÃ© avec ses paramÃ¨tres |
| **Cache** | Les Ã©tapes non modifiÃ©es ne sont pas re-exÃ©cutÃ©es |
| **TraÃ§abilitÃ©** | Visualisation du DAG (Directed Acyclic Graph) |
| **ModularitÃ©** | Chaque step peut Ãªtre rÃ©utilisÃ©e ailleurs |

---

## 10. Optimisation des HyperparamÃ¨tres avec Optuna

### ğŸ“„ Fichier : `src/optimize_hyperparameters.py`

### ğŸ”§ Ce que fait le code

**Optuna** recherche automatiquement les **meilleurs hyperparamÃ¨tres** pour minimiser le RMSE.

### ğŸ“ Espace de Recherche

```python
def objective(trial, X_train, y_train, X_test, y_test):
    params = {
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'n_estimators': trial.suggest_int('n_estimators', 50, 300),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
        'gamma': trial.suggest_float('gamma', 0.0, 5.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),
    }
    
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    return rmse  # Optuna minimise cette valeur
```

### ğŸ“ Explication des HyperparamÃ¨tres

| ParamÃ¨tre | Plage | Description |
|-----------|-------|-------------|
| `learning_rate` | 0.01-0.3 | Vitesse d'apprentissage (petit = lent mais prÃ©cis) |
| `max_depth` | 3-10 | Profondeur des arbres (grand = complexe) |
| `n_estimators` | 50-300 | Nombre d'arbres |
| `subsample` | 0.6-1.0 | Fraction des donnÃ©es par arbre |
| `colsample_bytree` | 0.6-1.0 | Fraction des features par arbre |
| `min_child_weight` | 1-10 | Poids minimum des feuilles |
| `gamma` | 0-5 | RÃ©gularisation par Ã©lagage |
| `reg_alpha` | 0-5 | RÃ©gularisation L1 |
| `reg_lambda` | 0-5 | RÃ©gularisation L2 |

### ğŸ“ L'Algorithme TPE (Tree-structured Parzen Estimator)

Optuna utilise **TPE** au lieu d'une recherche alÃ©atoire :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ALGORITHME TPE                                 â”‚
â”‚                                                                  â”‚
â”‚   Trial 1: learning_rate=0.15 â†’ RMSE=52.1                       â”‚
â”‚   Trial 2: learning_rate=0.08 â†’ RMSE=51.5  â† meilleur!          â”‚
â”‚   Trial 3: learning_rate=0.05 â†’ RMSE=51.2  â† meilleur!          â”‚
â”‚                                                                  â”‚
â”‚   TPE apprend: "les petits learning_rate sont meilleurs"        â”‚
â”‚   â†’ Il explore davantage autour de 0.05                         â”‚
â”‚                                                                  â”‚
â”‚   Trial 10: learning_rate=0.046 â†’ RMSE=50.71 â† OPTIMAL!        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ RÃ©sultats de l'Optimisation

**Meilleurs hyperparamÃ¨tres trouvÃ©s (Trial #11) :**
```python
{
    'learning_rate': 0.046,       # Plus petit que baseline (0.1)
    'max_depth': 3,               # Plus petit que baseline (6)
    'n_estimators': 287,          # Plus grand que baseline (100)
    'subsample': 0.969,
    'colsample_bytree': 0.782,
    'min_child_weight': 4,
    'gamma': 0.997,
    'reg_alpha': 2.136,
    'reg_lambda': 2.286
}
```

**AmÃ©lioration avec Feature Engineering :**
| ModÃ¨le | RMSE | AmÃ©lioration |
|--------|------|--------------|
| Baseline (raw sensors) | 51.35 | - |
| Optuna (raw sensors) | 50.71 | -1.26% |
| **Avec Feature Engineering** | **18.64** | **-63.7%** âœ¨ |

> **Note :** L'amÃ©lioration majeure vient du feature engineering (rolling windows, RUL clipping, normalisation), pas de l'optimisation Optuna seule.

---

## 11. API REST avec FastAPI

### ğŸ“„ Fichier : `api/main.py`

### ğŸ”§ Ce que fait le code

**FastAPI** crÃ©e une API HTTP pour servir les prÃ©dictions du modÃ¨le.

### ğŸ“ Endpoints de l'API

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/` | Information sur l'API |
| GET | `/health` | VÃ©rification de santÃ© |
| POST | `/predict` | PrÃ©diction RUL |
| GET | `/model-info` | DÃ©tails du modÃ¨le |
| GET | `/monitoring` | Statut du drift |
| GET | `/monitoring/reset` | Reset du buffer |

### ğŸ“ Le Schema d'EntrÃ©e (Pydantic)

```python
class EngineFeatures(BaseModel):
    """SchÃ©ma d'entrÃ©e pour les capteurs moteur."""
    
    # ParamÃ¨tres opÃ©rationnels
    setting_1: float
    setting_2: float
    setting_3: float
    
    # 21 capteurs
    s_1: float   # sera droppÃ©
    s_2: float
    ...
    s_21: float
```

**Pourquoi Pydantic ?**
- Validation automatique des types
- Documentation auto-gÃ©nÃ©rÃ©e (Swagger)
- Messages d'erreur clairs si donnÃ©es invalides

### ğŸ“ L'Endpoint `/predict` ExpliquÃ©

```python
@app.post("/predict", response_model=PredictionResponse)
async def predict_rul(features: EngineFeatures):
    """
    PrÃ©dit le RUL pour un moteur turbofan.
    """
    
    # 1. Convertir l'entrÃ©e en DataFrame
    input_data = pd.DataFrame([features.dict()])
    
    # 2. Supprimer les capteurs constants (comme Ã  l'entraÃ®nement)
    input_data = input_data.drop(columns=DROPPED_SENSORS)
    # DROPPED_SENSORS = ['s_1', 's_5', 's_10', 's_16', 's_18', 's_19']
    
    # 3. RÃ©ordonner les colonnes (ordre important pour XGBoost!)
    input_data = input_data[EXPECTED_FEATURES]
    
    # 4. CrÃ©er DMatrix pour XGBoost
    dmatrix = xgb.DMatrix(input_data)
    
    # 5. PrÃ©diction
    rul_pred = model.predict(dmatrix)[0]
    rul_pred = max(0.0, float(rul_pred))  # RUL ne peut pas Ãªtre nÃ©gatif
    
    # 6. DÃ©terminer le statut
    if rul_pred < 30:
        status = "Critical"    # ğŸ”´ Maintenance immÃ©diate
    elif rul_pred < 80:
        status = "Warning"     # ğŸŸ¡ Planifier maintenance
    else:
        status = "Healthy"     # ğŸŸ¢ Normal
    
    return PredictionResponse(
        RUL=round(rul_pred, 2),
        status=status,
        confidence="High"
    )
```

### ğŸ“ Exemple de RequÃªte/RÃ©ponse

**RequÃªte :**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "setting_1": -0.0007,
    "setting_2": -0.0004,
    "setting_3": 100.0,
    "s_1": 518.67,
    "s_2": 641.82,
    ...
    "s_21": 23.4190
  }'
```

**RÃ©ponse :**
```json
{
  "RUL": 112.45,
  "status": "Healthy",
  "confidence": "High"
}
```

### ğŸ“ Swagger UI Auto-gÃ©nÃ©rÃ©

Accessible Ã  `http://localhost:8000/docs` :
- Interface interactive pour tester les endpoints
- Documentation auto-gÃ©nÃ©rÃ©e depuis le code
- Exemples de requÃªtes

---

## 12. Conteneurisation avec Docker

### ğŸ“„ Fichier : `Dockerfile`

### ğŸ”§ Ce que fait le code

```dockerfile
# Image de base Python lÃ©gÃ¨re
FROM python:3.9-slim

# RÃ©pertoire de travail dans le conteneur
WORKDIR /app

# Variables d'environnement
ENV PYTHONUNBUFFERED=1 \           # Logs en temps rÃ©el
    PYTHONDONTWRITEBYTECODE=1 \    # Pas de fichiers .pyc
    PIP_NO_CACHE_DIR=1             # Pas de cache pip

# Installation des dÃ©pendances systÃ¨me
RUN apt-get update && apt-get install -y gcc && rm -rf /var/lib/apt/lists/*

# Copie et installation des dÃ©pendances Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copie du code de l'application
COPY api/ ./api/
COPY src/ ./src/
COPY model_optimized.ubj .

# CrÃ©ation d'un utilisateur non-root (sÃ©curitÃ©)
RUN useradd -m -u 1000 apiuser && chown -R apiuser:apiuser /app
USER apiuser

# Port exposÃ©
EXPOSE 8000

# Health check automatique
HEALTHCHECK --interval=30s --timeout=3s \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Commande de dÃ©marrage
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### ğŸ“ Explication Ligne par Ligne

| Instruction | Explication |
|-------------|-------------|
| `FROM python:3.9-slim` | Image lÃ©gÃ¨re avec Python 3.9 (~150 Mo vs ~1 Go pour l'image complÃ¨te) |
| `WORKDIR /app` | Tous les chemins seront relatifs Ã  `/app` |
| `ENV PYTHONUNBUFFERED=1` | Les prints Python apparaissent immÃ©diatement dans les logs |
| `RUN apt-get install gcc` | Compilateur C nÃ©cessaire pour certaines libs (XGBoost) |
| `COPY requirements.txt .` | Copie le fichier de dÃ©pendances |
| `RUN pip install...` | Installe les dÃ©pendances (fait en premier pour le cache) |
| `COPY api/ ./api/` | Copie le code source |
| `USER apiuser` | L'application tourne en tant qu'utilisateur non-root (sÃ©curitÃ©) |
| `HEALTHCHECK` | VÃ©rifie toutes les 30s que l'API rÃ©pond |
| `CMD ["uvicorn"...]` | Commande exÃ©cutÃ©e au dÃ©marrage du conteneur |

### ğŸ“„ Fichier : `docker-compose.yml`

```yaml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: turbofan-rul-api
    ports:
      - '8000:8000'          # Port hÃ´te:Port conteneur
    environment:
      - PYTHONUNBUFFERED=1
    healthcheck:
      test: ['CMD', 'python', '-c', "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped    # RedÃ©marre automatiquement si crash
    networks:
      - turbofan-network

networks:
  turbofan-network:
    driver: bridge
```

### ğŸ“ Commandes Docker

```bash
# Construire l'image
docker build -t turbofan-rul-api:latest .

# Lancer le conteneur
docker run -d -p 8000:8000 --name turbofan-api turbofan-rul-api:latest

# Ou avec docker-compose (plus simple)
docker-compose up -d

# Voir les logs
docker-compose logs -f

# ArrÃªter
docker-compose down
```

### ğŸ“ Avantages de Docker

| Avantage | Explication |
|----------|-------------|
| **PortabilitÃ©** | Fonctionne partout (Windows, Linux, Mac, Cloud) |
| **Isolation** | Pas de conflit avec le systÃ¨me hÃ´te |
| **ReproductibilitÃ©** | MÃªme environnement en dev et prod |
| **ScalabilitÃ©** | Facile Ã  rÃ©pliquer pour gÃ©rer plus de charge |

---

## 13. CI/CD avec GitHub Actions

### ğŸ“„ Fichier : `.github/workflows/ci_cd.yaml`

### ğŸ”§ Ce que fait le workflow

Le pipeline CI/CD s'exÃ©cute **automatiquement** Ã  chaque push sur `main` :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE CI/CD                                    â”‚
â”‚                                                                      â”‚
â”‚   Push to main                                                       â”‚
â”‚        â”‚                                                             â”‚
â”‚        â–¼                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚   Test & Lint    â”‚  â† flake8, black, pytest                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚            â”‚                                                         â”‚
â”‚            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚            â–¼                 â–¼                 â–¼                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚ Build Docker   â”‚ â”‚ ML Pipeline  â”‚ â”‚ Security     â”‚             â”‚
â”‚   â”‚                â”‚ â”‚ Simulation   â”‚ â”‚ Scan         â”‚             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚            â”‚                 â”‚                 â”‚                    â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                              â”‚                                       â”‚
â”‚                              â–¼                                       â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                    â”‚ Deploy Summary   â”‚                             â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ Job 1 : Test & Lint

```yaml
test-and-lint:
  steps:
    # VÃ©rification de la syntaxe Python
    - name: Lint with flake8
      run: |
        flake8 src api --select=E9,F63,F7,F82  # Erreurs critiques
        flake8 src api --max-line-length=120   # Style

    # VÃ©rification du formatage
    - name: Check code formatting
      run: black --check src api

    # ExÃ©cution des tests
    - name: Run unit tests
      run: pytest test_api.py -v
```

**Outils utilisÃ©s :**
| Outil | Fonction |
|-------|----------|
| `flake8` | DÃ©tecte erreurs de syntaxe et violations PEP8 |
| `black` | VÃ©rifie le formatage du code |
| `pytest` | ExÃ©cute les tests unitaires |

### ğŸ“ Job 2 : Build Docker

```yaml
build-container:
  needs: test-and-lint  # Attend que les tests passent
  steps:
    - name: Build Docker image
      run: docker build -t turbofan-rul-api:latest .

    - name: Test Docker image (smoke test)
      run: |
        docker run -d --name test-api -p 8000:8000 turbofan-rul-api:latest
        sleep 10
        curl -f http://localhost:8000/health  # VÃ©rifie que l'API rÃ©pond
        docker stop test-api
```

### ğŸ“ Job 3 : ML Pipeline Simulation

```yaml
ml-pipeline-simulation:
  steps:
    # VÃ©rifie que les modules s'importent correctement
    - name: Run preprocessing test
      run: |
        python -c "from src.data_preprocessing import load_and_process_data"

    # VÃ©rifie que le modÃ¨le se charge
    - name: Run training pipeline
      run: |
        python -c "
        import xgboost as xgb
        model = xgb.Booster()
        model.load_model('model_optimized.ubj')
        print('âœ… Model loaded successfully')
        "
```

### ğŸ“ Job 4 : Security Scan

```yaml
security-scan:
  steps:
    # Scan avec Trivy pour les vulnÃ©rabilitÃ©s
    - uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'

    # VÃ©rifie les dÃ©pendances Python
    - name: Check dependencies
      run: |
        pip install safety
        safety check  # DÃ©tecte les vulnÃ©rabilitÃ©s connues
```

### ğŸ“ Badge CI/CD

Dans le README, le badge montre le statut du pipeline :

```markdown
![CI/CD](https://github.com/AymenMB/turbofan-predictive-maintenance-mlops/workflows/CI%2FCD%20Pipeline%20-%20Turbofan%20RUL%20MLOps/badge.svg)
```

âœ… Vert = Pipeline rÃ©ussi
âŒ Rouge = Pipeline Ã©chouÃ©

---

## 14. Monitoring et DÃ©tection de Drift (Bonus)

### ğŸ“„ Fichiers : `api/main.py` (partie monitoring) + `simulate_drift.py`

### ğŸ”§ Ce qu'est le Data Drift

**Data Drift** = Les donnÃ©es en production **diffÃ¨rent** des donnÃ©es d'entraÃ®nement.

```
EntraÃ®nement (2024):          Production (2025):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ s_2 moyenne: 642.6  â”‚      â”‚ s_2 moyenne: 800.0  â”‚  â† DRIFT!
â”‚ s_3 moyenne: 1591.4 â”‚      â”‚ s_3 moyenne: 2000.0 â”‚  â† DRIFT!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Si les capteurs dÃ©rivent, le modÃ¨le peut faire des prÃ©dictions incorrectes!
```

### ğŸ“ ImplÃ©mentation du Monitoring

**Statistiques de rÃ©fÃ©rence (baseline) :**
```python
BASELINE_STATS = {
    'setting_1': -0.0001,
    'setting_2': 0.0002,
    'setting_3': 100.0,
    's_2': 642.6,
    's_3': 1591.4,
    # ... autres capteurs
}
```

**Buffer circulaire (derniÃ¨res 100 prÃ©dictions) :**
```python
from collections import deque
recent_predictions = deque(maxlen=100)
```

**DÃ©tection de drift :**
```python
@app.get("/monitoring")
async def monitor_drift():
    # 1. Calcule la moyenne des 100 derniÃ¨res requÃªtes
    recent_means = pd.DataFrame(recent_features).mean()
    
    # 2. Compare avec la baseline
    for feature in EXPECTED_FEATURES:
        baseline = BASELINE_STATS[feature]
        recent = recent_means[feature]
        
        # 3. Calcule la dÃ©viation en %
        deviation = abs(recent - baseline) / abs(baseline)
        
        # 4. Flag si dÃ©viation > 20%
        if deviation > 0.20:
            drifted_features.append(feature)
    
    return {
        "drift_detected": len(drifted_features) > 0,
        "drifted_features": drifted_features
    }
```

### ğŸ“ Script de Simulation

**`simulate_drift.py`** simule un scÃ©nario de drift :

**Phase 1 : DonnÃ©es normales**
```python
# Envoie 25 requÃªtes avec des donnÃ©es normales
for row in normal_data:
    requests.post("/predict", json=row)

# RÃ©sultat: No drift detected âœ“
```

**Phase 2 : DonnÃ©es corrompues**
```python
# Multiplie les capteurs par 1.5 (simule des capteurs dÃ©faillants)
for row in corrupted_data:
    row['s_2'] *= 1.5
    row['s_3'] *= 1.5
    requests.post("/predict", json=row)

# RÃ©sultat: DRIFT DETECTED! 17 features exceeding threshold âš ï¸
```

### ğŸ“ RÃ©ponse du Monitoring

```json
{
  "drift_detected": true,
  "status": "Data Drift Warning - 17 feature(s) exceed threshold",
  "metrics": {
    "max_deviation_pct": 50.0,
    "threshold_pct": 20.0,
    "drifted_features": [
      {"feature": "s_2", "deviation_pct": 50.0},
      {"feature": "s_3", "deviation_pct": 50.0},
      ...
    ]
  },
  "recent_requests": 50
}
```

---

## 15. RÃ©sumÃ© des Livrables

### âœ… Checklist Finale

| # | Exigence du Cahier des Charges | Statut | Fichier(s) |
|---|-------------------------------|--------|------------|
| 1 | Git repository propre | âœ… | GitHub repo |
| 2 | Structure claire avec README | âœ… | README.md, DOCUMENTATION.md |
| 3 | Docker + docker-compose | âœ… | Dockerfile, docker-compose.yml |
| 4 | DVC pour versioning donnÃ©es | âœ… | data/raw.dvc |
| 5 | MLflow experiment tracking | âœ… | mlruns/, src/train_model.py |
| 6 | Pipeline ZenML | âœ… | pipelines/, steps/ |
| 7 | Optuna optimization | âœ… | src/optimize_hyperparameters.py |
| 8 | API d'infÃ©rence | âœ… | api/main.py |
| 9 | CI/CD GitHub Actions | âœ… | .github/workflows/ci_cd.yaml |
| 10 | Tests | âœ… | test_api.py, test_pipeline.py |
| **Bonus** | Monitoring & Drift | âœ… | simulate_drift.py, /monitoring |

### ğŸ“Š Performances Finales

| MÃ©trique | Baseline (raw) | Avec Feature Engineering | AmÃ©lioration |
|----------|----------------|--------------------------|---------------|
| **RMSE** | 51.35 | **18.64** | **-63.7%** âœ¨ |
| MAE | 36.55 | ~14 | -61.7% |
| RÂ² | 0.5609 | ~0.79 | +40% |

### ğŸš€ Commandes Essentielles

```bash
# Setup
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt

# RÃ©cupÃ©rer les donnÃ©es
dvc pull

# Lancer l'API
python -m uvicorn api.main:app --reload --port 8000

# Lancer le pipeline ZenML
python run_pipeline.py

# Optimisation Optuna
python src/optimize_hyperparameters.py

# Docker
docker-compose up -d

# MLflow UI
mlflow ui --port 5000

# Tests
python test_api.py
```

### ğŸ”— Points d'AccÃ¨s

| Service | URL |
|---------|-----|
| API Swagger | http://localhost:8000/docs |
| API Health | http://localhost:8000/health |
| API Predict | http://localhost:8000/predict |
| API Monitoring | http://localhost:8000/monitoring |
| MLflow UI | http://localhost:5000 |
| ZenML Dashboard | http://localhost:8237 |

---

## ğŸ“š Glossaire

| Terme | DÃ©finition |
|-------|------------|
| **RUL** | Remaining Useful Life - DurÃ©e de vie restante en cycles |
| **RMSE** | Root Mean Squared Error - Mesure d'erreur standard |
| **XGBoost** | Algorithme de gradient boosting optimisÃ© |
| **DVC** | Data Version Control - Versionne les fichiers volumineux |
| **MLflow** | Plateforme de suivi d'expÃ©riences ML |
| **ZenML** | Orchestrateur de pipelines ML |
| **Optuna** | Framework d'optimisation d'hyperparamÃ¨tres |
| **FastAPI** | Framework Python pour crÃ©er des APIs REST |
| **Docker** | Plateforme de conteneurisation |
| **CI/CD** | Continuous Integration / Continuous Deployment |
| **Data Drift** | Changement de distribution des donnÃ©es en production |

---

**Auteur :** Aymen Mabrouk  
**Institution :** Ã‰cole Polytechnique Sousse  
**Version :** 1.1.0  
**Date :** DÃ©cembre 2025

---

ğŸ“ **Ce document explique chaque composant du projet MLOps de maniÃ¨re dÃ©taillÃ©e pour une prÃ©sentation complÃ¨te au professeur.**
