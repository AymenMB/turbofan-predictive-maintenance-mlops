# ğŸ›©ï¸ AeroGuard AI - Mini-projet MLOps

<div align="center">

![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)
![Docker](https://img.shields.io/badge/docker-ready-brightgreen.svg)
![Azure](https://img.shields.io/badge/azure-deployed-0078D4.svg)
![MLflow](https://img.shields.io/badge/mlflow-tracking-orange.svg)
![ZenML](https://img.shields.io/badge/zenml-pipeline-purple.svg)

**PrÃ©diction de la DurÃ©e de Vie Restante (RUL) des Moteurs Turbofan**

*Un workflow MLOps complet de bout en bout*

</div>

---

## ğŸ“‹ Informations du Projet

| | |
|---|---|
| **Ã‰tudiant** | Aymen MABROUK |
| **Encadrant** | Dr. Salah GONTARA |
| **Institution** | Ã‰cole Polytechnique Sousse |
| **Module** | MLOps |
| **AnnÃ©e** | 2025-2026 |

---

## ğŸ¯ Objectif du Projet

Ce mini-projet MLOps implÃ©mente un **workflow complet de bout en bout** pour la maintenance prÃ©dictive des moteurs turbofan, incluant :

- âœ… Gestion du code (Git)
- âœ… Conteneurisation (Docker / Docker Compose)
- âœ… Versioning des donnÃ©es (DVC)
- âœ… Suivi d'expÃ©riences (MLflow)
- âœ… Pipeline ML (ZenML)
- âœ… Optimisation (Optuna)
- âœ… CI/CD (GitHub Actions)
- âœ… DÃ©ploiement (API FastAPI sur Azure)
- âœ… **Bonus : Monitoring** (dÃ©tection de drift)
- âœ… **Bonus : Retrain automatique**

---

## ğŸ“Š Cas d'Usage & Dataset

### Dataset : NASA C-MAPSS (FD001)

| CaractÃ©ristique | Valeur |
|-----------------|--------|
| **Source** | NASA Prognostics Center |
| **Type** | SÃ©rie temporelle / RÃ©gression |
| **Taille** | 100 moteurs, ~21,000 cycles |
| **Features** | 21 capteurs + 3 paramÃ¨tres opÃ©rationnels |
| **Target** | RUL (Remaining Useful Life) |

### ModÃ¨le : XGBoost avec Feature Engineering

| MÃ©trique | Valeur |
|----------|--------|
| **RMSE** | **18.64 cycles** |
| **RÂ²** | **0.79** |
| **AmÃ©lioration** | 63% vs baseline |

---

## ğŸ“ Structure du Projet

```
ğŸ“¦ turbofan-predictive-maintenance-mlops
â”œâ”€â”€ ğŸ“‚ api/                    # FastAPI application
â”‚   â”œâ”€â”€ main.py               # Endpoints API
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ğŸ“‚ data/                   # Dataset (DVC)
â”‚   â”œâ”€â”€ raw/                  # DonnÃ©es brutes
â”‚   â””â”€â”€ raw.dvc               # Fichier DVC tracking
â”œâ”€â”€ ğŸ“‚ pipelines/              # ZenML pipelines
â”‚   â””â”€â”€ training_pipeline.py  # Pipeline d'entraÃ®nement
â”œâ”€â”€ ğŸ“‚ steps/                  # ZenML steps
â”‚   â”œâ”€â”€ ingest_data.py        # Ingestion donnÃ©es
â”‚   â”œâ”€â”€ clean_data.py         # PrÃ©traitement
â”‚   â”œâ”€â”€ train_model.py        # EntraÃ®nement
â”‚   â””â”€â”€ evaluate_model.py     # Ã‰valuation
â”œâ”€â”€ ğŸ“‚ src/                    # Code ML
â”‚   â”œâ”€â”€ data_preprocessing.py # Feature engineering
â”‚   â”œâ”€â”€ optimize_hyperparameters.py # Optuna
â”‚   â””â”€â”€ train.py              # Script training
â”œâ”€â”€ ğŸ“‚ .github/workflows/      # CI/CD
â”‚   â”œâ”€â”€ ci_cd.yaml            # Pipeline CI
â”‚   â””â”€â”€ deploy-azure.yaml     # DÃ©ploiement Azure
â”œâ”€â”€ ğŸ“‚ mlruns/                 # MLflow experiments
â”œâ”€â”€ ğŸ“‚ screenshots/            # Captures d'Ã©cran
â”œâ”€â”€ ğŸ“„ Dockerfile              # Image Docker
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # Orchestration
â”œâ”€â”€ ğŸ“„ retrain.py              # Script retrain auto
â”œâ”€â”€ ğŸ“„ simulate_drift.py       # Simulation drift
â””â”€â”€ ğŸ“„ README.md               # Ce fichier
```

---

## ğŸ”§ 3.2 Gestion du Code (Git)

### Branches
```bash
$ git branch -a
* main                    # Production
  dev                     # DÃ©veloppement
  remotes/origin/main
  remotes/origin/dev
```

### Tags (Versioning)
```bash
$ git tag -l
v1    # Version initiale
v2    # AmÃ©liorations
v3    # Version finale avec bonus
```

### Repository GitHub
ğŸ”— https://github.com/AymenMB/turbofan-predictive-maintenance-mlops

---

## ğŸ³ 3.3 Conteneurisation (Docker)

### Dockerfile
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements-api.txt ./requirements.txt
RUN pip install --no-cache-dir -r requirements.txt
COPY api/ ./api/
COPY model_optimized.ubj .
EXPOSE 8000
HEALTHCHECK --interval=30s CMD python -c "import requests; requests.get('http://localhost:8000/health')"
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### docker-compose.yml
```yaml
version: '3.8'
services:
  api:
    build: .
    ports:
      - '8000:8000'
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
```

### Commandes
```bash
# Lancer le conteneur
docker-compose up -d

# VÃ©rifier le status
docker-compose ps
# RÃ©sultat: turbofan-rul-api   Up (healthy)   0.0.0.0:8000->8000/tcp
```

---

## ğŸ“¦ 3.4 Versioning des DonnÃ©es (DVC)

### ğŸ¯ Ce que nous avons fait
DVC (Data Version Control) permet de versionner les gros fichiers de donnÃ©es sans les mettre dans Git.

**Actions rÃ©alisÃ©es:**
1. InitialisÃ© DVC avec `dvc init`
2. TrackÃ© le dossier `data/raw/` contenant le dataset NASA
3. ConfigurÃ© un remote de stockage pour sauvegarder les donnÃ©es
4. CrÃ©Ã© le fichier `data/raw.dvc` qui rÃ©fÃ©rence les donnÃ©es

### Configuration
```bash
$ dvc remote list
local_storage   D:\dvc_store    (default)
```

### Fichiers trackÃ©s
```
data/raw.dvc
â”œâ”€â”€ 12 fichiers (44.9 MB total)
â”œâ”€â”€ train_FD001.txt   # DonnÃ©es d'entraÃ®nement (100 moteurs)
â”œâ”€â”€ test_FD001.txt    # DonnÃ©es de test
â””â”€â”€ RUL_FD001.txt     # Labels RUL pour le test
```

### ğŸ” Comment vÃ©rifier
```bash
# VÃ©rifier que les donnÃ©es sont synchronisÃ©es
$ dvc status
Data and pipelines are up to date.   âœ… Signifie que tout est OK!

# RÃ©cupÃ©rer les donnÃ©es (pour un nouveau clone)
$ dvc pull
# TÃ©lÃ©charge les 12 fichiers depuis le remote

# Sauvegarder les donnÃ©es modifiÃ©es
$ dvc push
# Envoie les donnÃ©es vers le remote
```

### ğŸ“ Fichier data/raw.dvc (contenu)
```yaml
outs:
- md5: 4f031cda497f36cac6922c0e7238b1f9.dir
  size: 44913306
  nfiles: 12
  hash: md5
  path: raw
```

---

## ğŸ“ˆ 3.5 Experiment Tracking (MLflow)

### ğŸ¯ Ce que nous avons fait
MLflow permet de tracker toutes les expÃ©riences ML: paramÃ¨tres, mÃ©triques et modÃ¨les.

**Actions rÃ©alisÃ©es:**
1. IntÃ©grÃ© MLflow dans les scripts d'entraÃ®nement
2. CrÃ©Ã© des expÃ©riences pour organiser les runs
3. LoggÃ© les hyperparamÃ¨tres de chaque run
4. LoggÃ© les mÃ©triques (RMSE, MAE, RÂ²)
5. SauvegardÃ© les modÃ¨les comme artefacts

### ğŸ“‚ Structure des fichiers MLflow
```
mlruns/
â”œâ”€â”€ 1/                          # Experiment 1: Turbofan_RUL_Prediction
â”‚   â”œâ”€â”€ 5bf6e15b.../           # Run 1
â”‚   â”‚   â”œâ”€â”€ artifacts/         # ModÃ¨les sauvegardÃ©s
â”‚   â”‚   â”œâ”€â”€ metrics/           # RMSE, MAE, RÂ²
â”‚   â”‚   â””â”€â”€ params/            # HyperparamÃ¨tres
â”‚   â”œâ”€â”€ 6371496a.../           # Run 2
â”‚   â”œâ”€â”€ 99283140.../           # Run 3
â”‚   â””â”€â”€ d013f742.../           # Run 4
â””â”€â”€ 2/                          # Experiment 2: Optuna
```

### Runs enregistrÃ©s (4+ runs)
| Run | RMSE | RÂ² | Description |
|-----|------|-----|-------------|
| Baseline | 50.71 | 0.56 | Sans feature engineering |
| Feature Engineering | 18.89 | 0.78 | Rolling windows + normalization |
| Optuna Optimized | **18.64** | **0.79** | Meilleur run, hyperparamÃ¨tres optimaux |
| Variations | ~19-22 | 0.75+ | Tests avec diffÃ©rents paramÃ¨tres |

### Code d'intÃ©gration (extrait de train_model.py)
```python
import mlflow

# Configurer l'expÃ©rience
mlflow.set_experiment("Turbofan_RUL_Prediction")

# Logger les paramÃ¨tres
mlflow.log_param("n_estimators", 300)
mlflow.log_param("learning_rate", 0.05)

# Logger les mÃ©triques
mlflow.log_metric("rmse", 18.64)
mlflow.log_metric("r2", 0.79)

# Sauvegarder le modÃ¨le
mlflow.log_artifact("model_optimized.ubj")
```

### ğŸ” Comment vÃ©rifier
```bash
# Lancer l'interface MLflow
mlflow ui --port 5000

# Ouvrir dans le navigateur
http://localhost:5000

# Vous verrez:
# - Liste des experiments
# - Tous les runs avec leurs mÃ©triques
# - Graphiques de comparaison
# - Artefacts tÃ©lÃ©chargeables
```

### Artefacts loggÃ©s pour chaque run
- âœ… **ParamÃ¨tres**: learning_rate, max_depth, n_estimators, subsample, etc.
- âœ… **MÃ©triques**: RMSE, MAE, RÂ², durÃ©e d'entraÃ®nement
- âœ… **Artefacts**: model_optimized.ubj, feature_columns.txt

---

## ğŸ”„ 3.6 Pipeline MLOps (ZenML)

### ğŸ¯ Ce que nous avons fait
ZenML orchestre le pipeline ML en Ã©tapes modulaires et reproductibles.

**Actions rÃ©alisÃ©es:**
1. CrÃ©Ã© 4 steps rÃ©utilisables dans `steps/`
2. AssemblÃ© les steps dans `pipelines/training_pipeline.py`
3. Chaque step a ses inputs/outputs typÃ©s
4. IntÃ©gration avec MLflow pour le tracking

### Architecture du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ingest_data â”‚â”€â”€â”€â”€â–¶â”‚  clean_data  â”‚â”€â”€â”€â”€â–¶â”‚  train_model â”‚â”€â”€â”€â”€â–¶â”‚evaluate_modelâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Load            Feature               XGBoost             RMSE, MAE,
    FD001.txt        Engineering          Training               RÂ²
```

### ğŸ“‚ Fichiers du pipeline

#### 1. `pipelines/training_pipeline.py` (58 lignes)
```python
from zenml import pipeline
from steps import ingest_data, clean_data, train_model, evaluate_model

@pipeline
def training_pipeline(data_path: str = "data/raw/train_FD001.txt"):
    raw_data = ingest_data(data_path=data_path)      # Step 1
    cleaned_data = clean_data(df=raw_data)           # Step 2
    model = train_model(df=cleaned_data)             # Step 3
    metrics = evaluate_model(model=model, df=cleaned_data)  # Step 4
    return metrics
```

#### 2. `steps/ingest_data.py` - Chargement des donnÃ©es
- Lit le fichier `train_FD001.txt`
- Parse les 24 colonnes (unit, cycle, settings, sensors)
- Retourne un DataFrame pandas

#### 3. `steps/clean_data.py` - Feature Engineering  
- Calcule le RUL pour chaque engine
- Applique le RUL clipping Ã  125 cycles
- CrÃ©e les rolling features (mean, std sur 5 cycles)
- Normalise les capteurs

#### 4. `steps/train_model.py` (118 lignes) - EntraÃ®nement
- Split time-series aware (engines 1-80 train, 81-100 test)
- EntraÃ®ne XGBoost avec les hyperparamÃ¨tres optimaux
- IntÃ¨gre MLflow pour le logging

#### 5. `steps/evaluate_model.py` - Ã‰valuation
- Calcule RMSE, MAE, RÂ²
- Log les mÃ©triques dans MLflow
- Affiche le rapport de performance

### ğŸ” Comment exÃ©cuter
```bash
# ExÃ©cuter le pipeline
python run_pipeline.py

# Output attendu:
# ======================================================================
# TURBOFAN RUL PREDICTION - ZenML PIPELINE
# ======================================================================
# Initiating a new run for the pipeline: training_pipeline.
# Step ingest_data has started.
# Step clean_data has started.
# Step train_model has started.
# Step evaluate_model has started.
# Pipeline run completed successfully!
```

---

## âš™ï¸ 3.7 Optimisation (Optuna)

### ğŸ¯ Ce que nous avons fait
Optuna effectue une recherche automatique des meilleurs hyperparamÃ¨tres.

**Actions rÃ©alisÃ©es:**
1. CrÃ©Ã© `src/optimize_hyperparameters.py` (230 lignes)
2. DÃ©fini l'espace de recherche pour 9 hyperparamÃ¨tres
3. ExÃ©cutÃ© 30 trials (plus que le minimum de 5-10)
4. LoggÃ© chaque trial dans MLflow
5. SauvegardÃ© le meilleur modÃ¨le

### ğŸ“‚ Fichier: `src/optimize_hyperparameters.py`
```python
import optuna
import mlflow

def objective(trial, X_train, y_train, X_test, y_test):
    # Espace de recherche pour 9 hyperparamÃ¨tres
    params = {
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15),
        'max_depth': trial.suggest_int('max_depth', 3, 8),
        'n_estimators': trial.suggest_int('n_estimators', 200, 500),
        'subsample': trial.suggest_float('subsample', 0.7, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),
        'gamma': trial.suggest_float('gamma', 0.0, 2.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 3.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 3.0),
    }
    
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train)
    rmse = calculate_rmse(model, X_test, y_test)
    
    # Log to MLflow
    with mlflow.start_run(nested=True):
        mlflow.log_params(params)
        mlflow.log_metric("test_rmse", rmse)
    
    return rmse  # Optuna minimise cette valeur

# Configuration de l'Ã©tude (30 trials)
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=30)
```

### HyperparamÃ¨tres optimisÃ©s
| ParamÃ¨tre | Espace de recherche | Meilleure valeur |
|-----------|---------------------|------------------|
| learning_rate | [0.01, 0.15] | **0.05** |
| max_depth | [3, 8] | **4** |
| n_estimators | [200, 500] | **300** |
| subsample | [0.7, 1.0] | **0.85** |
| colsample_bytree | [0.6, 1.0] | **0.8** |
| min_child_weight | [1, 7] | **3** |
| gamma | [0.0, 2.0] | **0.1** |
| reg_alpha | [0.0, 3.0] | **0.5** |
| reg_lambda | [0.0, 3.0] | **1.0** |

### ğŸ” Comment exÃ©cuter
```bash
python src/optimize_hyperparameters.py

# Output:
# [1/5] Loading and preprocessing data...
# [2/5] Creating Optuna study...
# [3/5] Running optimization (30 trials)...
#   Trial 1: RMSE = 22.45
#   Trial 2: RMSE = 19.87
#   ...
#   Trial 30: RMSE = 18.91
# 
# ğŸ¯ Best RMSE: 18.64 cycles
# âœ“ Improvement from baseline: 32.07 cycles (63.2% better)
```

### RÃ©sultats
```
ğŸ¯ Best RMSE: 18.64 cycles
âœ“ AmÃ©lioration de 63% par rapport au baseline (50.71 â†’ 18.64)
âœ“ 30 trials exÃ©cutÃ©s et loggÃ©s dans MLflow
âœ“ Meilleur modÃ¨le sauvegardÃ©: model_optimized.ubj
```

---

## ğŸš€ 3.8 CI/CD (GitHub Actions)

### Pipeline CI (`ci_cd.yaml`)
```yaml
jobs:
  test-and-lint:
    - Checkout code
    - Setup Python 3.9
    - Install dependencies
    - Lint with flake8
    - Run pytest
  
  build-container:
    - Build Docker image
    - Test health endpoint
    - Push to registry
```

### Pipeline Deploy (`deploy-azure.yaml`)
```yaml
jobs:
  deploy:
    - Login to Azure
    - Push to Azure Container Registry
    - Deploy to Azure Container Apps
```

---

## ğŸŒ 3.9 DÃ©ploiement (Serving)

### API FastAPI - Endpoints

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/` | Informations API |
| GET | `/health` | Health check |
| POST | `/predict` | PrÃ©diction RUL |
| POST | `/predict/batch` | PrÃ©diction batch |
| GET | `/model-info` | MÃ©tadonnÃ©es modÃ¨le |
| GET | `/monitoring` | DÃ©tection drift |
| GET | `/monitoring/reset` | Reset monitoring |

### Screenshot - API Swagger UI
![API Swagger UI](screenshots/api_swagger_ui.png)

### URLs de dÃ©ploiement

| Service | URL | Status |
|---------|-----|--------|
| **Local Docker** | http://localhost:8000 | âœ… Running |
| **Azure Cloud** | https://aeroguard-api.salmonfield-cb3d4cec.francecentral.azurecontainerapps.io/ | âœ… Deployed |
| **Streamlit UI** | https://turbofan-predictive-m-cuczeudvjuhekghyeqtcj9.streamlit.app/ | âœ… Online |

### Screenshot - Streamlit Prediction
![Streamlit Prediction](screenshots/streamlit_prediction.png)

### Simulation v1 â†’ v2 â†’ Rollback
```bash
# Deploy v1
git checkout v1
docker-compose up -d --build

# Update to v2
git checkout v2
docker-compose up -d --build

# Rollback to v1
git checkout v1
docker-compose up -d --build

# Return to main
git checkout main
```

---

## ğŸ 4. Bonus ImplÃ©mentÃ©s

### Bonus 1: Monitoring (Drift Detection) âœ…

#### ğŸ¯ Ce que nous avons fait
Le monitoring dÃ©tecte quand les nouvelles donnÃ©es diffÃ¨rent significativement des donnÃ©es d'entraÃ®nement.

**Actions rÃ©alisÃ©es:**
1. CrÃ©Ã© l'endpoint `/monitoring` dans l'API
2. Stockage des 100 derniÃ¨res prÃ©dictions en mÃ©moire
3. Comparaison avec les statistiques baseline du training set
4. Seuil de drift: 20% de dÃ©viation

#### Code de l'endpoint (dans api/main.py)
```python
@app.get("/monitoring")
async def monitor_drift():
    # Compare recent predictions with baseline stats
    for feature in BASELINE_STATS:
        deviation = abs(recent_mean - baseline_val) / baseline_val
        if deviation > DRIFT_THRESHOLD:  # 20%
            drifted_features.append(feature)
    
    return {
        "drift_detected": len(drifted_features) > 0,
        "metrics": {...}
    }
```

#### ğŸ” Comment tester le monitoring
```bash
# 1. VÃ©rifier que l'API tourne
curl http://localhost:8000/health

# 2. Appeler l'endpoint monitoring
curl http://localhost:8000/monitoring

# RÃ©ponse attendue:
{
  "drift_detected": false,
  "status": "No data available for monitoring",
  "metrics": {},
  "recent_requests": 0
}

# 3. Faire quelques prÃ©dictions, puis re-vÃ©rifier
curl -X POST http://localhost:8000/predict -H "Content-Type: application/json" -d '{...}'
curl http://localhost:8000/monitoring
# Maintenant vous verrez les statistiques!
```

#### Script de simulation: `simulate_drift.py` (313 lignes)
```bash
python simulate_drift.py

# Phase 1: Envoie 25 requÃªtes normales â†’ Pas de drift
# Phase 2: Envoie 25 requÃªtes corrompues (Ã—1.5) â†’ Drift dÃ©tectÃ©!
```

---

### Bonus 2: Retrain Automatique âœ…

#### ğŸ¯ Ce que nous avons fait
Script de rÃ©entraÃ®nement automatique dÃ©clenchÃ© par le drift ou manuellement.

**Actions rÃ©alisÃ©es:**
1. CrÃ©Ã© `retrain.py` (266 lignes)
2. VÃ©rifie le status de drift via l'API
3. Charge les donnÃ©es et rÃ©entraÃ®ne si nÃ©cessaire
4. Sauvegarde le nouveau modÃ¨le + backup de l'ancien
5. Log le retrain dans MLflow

#### Fichier: `retrain.py`
```python
def run_retrain(reason="manual"):
    # [1/4] Load training data
    X_train, y_train, X_test, y_test, feature_cols = load_training_data()
    
    # [2/4] Train model with best hyperparameters
    model = xgb.XGBRegressor(
        learning_rate=0.05, max_depth=4, n_estimators=300, ...
    )
    model.fit(X_train, y_train)
    
    # [3/4] Save model (backup old one first)
    backup_path = f"model_backup_{timestamp}.ubj"
    model.get_booster().save_model(MODEL_PATH)
    
    # [4/4] Log to MLflow
    mlflow.log_metric("rmse", rmse)
    mlflow.log_artifact(MODEL_PATH)
```

#### ğŸ” Comment utiliser
```bash
# VÃ©rifier si retrain nÃ©cessaire (sans exÃ©cuter)
python retrain.py --check-only
# Output: "âœ“ No drift detected" ou "âš ï¸ Data drift detected!"

# Forcer le retrain maintenant
python retrain.py --force --reason "scheduled_weekly"
# Output:
# [1/4] Loading training data... âœ“
# [2/4] Training model... âœ“ RMSE: 18.64 cycles
# [3/4] Saving model... âœ“
# [4/4] Logging results... âœ“
# âœ… RETRAIN COMPLETE

# Retrain automatique si drift dÃ©tectÃ©
python retrain.py
# VÃ©rifie /monitoring, puis retrain si drift_detected=true
```

---

## ğŸ“Š 5. Livrables

| Livrable | Status | Fichier/URL |
|----------|--------|-------------|
| Lien GitHub | âœ… | https://github.com/AymenMB/turbofan-predictive-maintenance-mlops |
| Dockerfile | âœ… | `Dockerfile` |
| docker-compose.yml | âœ… | `docker-compose.yml` |
| Configuration DVC | âœ… | `data/raw.dvc`, `.dvc/config` |
| MLflow experiments | âœ… | `mlruns/` (4+ runs) |
| ZenML pipeline | âœ… | `pipelines/training_pipeline.py` |
| CI/CD | âœ… | `.github/workflows/*.yaml` |
| API dÃ©ployÃ©e | âœ… | Azure Container Apps |
| Documentation | âœ… | `README.md`, `MLOPS_STEP_BY_STEP.md` |

---

## ğŸš€ Quick Start

### 1. Cloner le repository
```bash
git clone https://github.com/AymenMB/turbofan-predictive-maintenance-mlops.git
cd turbofan-predictive-maintenance-mlops
```

### 2. Installer les dÃ©pendances
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### 3. RÃ©cupÃ©rer les donnÃ©es
```bash
dvc pull
```

### 4. Lancer l'API avec Docker
```bash
docker-compose up -d
```

### 5. Tester l'API
```bash
curl http://localhost:8000/health
# {"status":"ok","model_loaded":true}
```

### 6. Ouvrir Swagger UI
```
http://localhost:8000/docs
```

---

## ğŸ“ˆ RÃ©sultats

### Performance du modÃ¨le

| MÃ©trique | Baseline | OptimisÃ© | AmÃ©lioration |
|----------|----------|----------|--------------|
| RMSE | 50.71 | **18.64** | -63% |
| RÂ² | 0.56 | **0.79** | +41% |

### Architecture dÃ©ployÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AZURE CLOUD                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Container        â”‚      â”‚ Azure Container Apps         â”‚    â”‚
â”‚  â”‚ Registry (ACR)   â”‚â”€â”€â”€â”€â”€â–¶â”‚  aeroguard-api              â”‚    â”‚
â”‚  â”‚ aeroguardacr     â”‚      â”‚  FastAPI + XGBoost          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚ HTTPS
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚    STREAMLIT CLOUD    â”‚                       â”‚
                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                  â”‚  â”‚   AeroGuard AI Dashboard               â”‚  â”‚
                  â”‚  â”‚   - Predict RUL                        â”‚  â”‚
                  â”‚  â”‚   - Batch Analysis                     â”‚  â”‚
                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Documentation Additionnelle

- [MLOPS_STEP_BY_STEP.md](MLOPS_STEP_BY_STEP.md) - Guide dÃ©taillÃ© pas Ã  pas
- [AZURE_DEPLOYMENT.md](AZURE_DEPLOYMENT.md) - Guide de dÃ©ploiement Azure
- [DOCUMENTATION.md](DOCUMENTATION.md) - Documentation technique

---

## ğŸ† Conclusion

Ce projet implÃ©mente **tous les 9 requirements** du cahier des charges Mini-projet MLOps ainsi que les **2 bonus optionnels** (Monitoring et Retrain automatique).

### âœ… Checklist finale

- [x] 3.1 Dataset public (NASA C-MAPSS) + ModÃ¨le baseline (XGBoost)
- [x] 3.2 Git avec branches (main/dev) et tags (v1/v2/v3)
- [x] 3.3 Docker + Docker Compose
- [x] 3.4 DVC pour versioning des donnÃ©es
- [x] 3.5 MLflow pour experiment tracking
- [x] 3.6 ZenML pour pipeline orchestration
- [x] 3.7 Optuna pour optimisation (30 trials)
- [x] 3.8 CI/CD avec GitHub Actions
- [x] 3.9 API dÃ©ployÃ©e sur Azure + simulation v1â†’v2â†’rollback
- [x] **Bonus 1:** Monitoring (drift detection)
- [x] **Bonus 2:** Retrain automatique

---

<div align="center">

**RÃ©alisÃ© par Aymen MABROUK**

*Sous la supervision de Dr. Salah GONTARA*

Ã‰cole Polytechnique Sousse | 2025-2026

</div>
